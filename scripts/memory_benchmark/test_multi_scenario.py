#!/usr/bin/env python3
"""
Simple test script for multi-scenario memory evaluation
"""

import asyncio
import sys
from pathlib import Path

# Add shared path for AICO modules
shared_path = Path(__file__).parent.parent.parent / "shared"
sys.path.insert(0, str(shared_path))

from .evaluator import MemoryIntelligenceEvaluator
from .scenarios import ScenarioLibrary

async def test_multi_scenario(reuse_user: bool = False):
    """
    Test the multi-scenario evaluation system
    
    Args:
        reuse_user: If True, reuse the same user across all scenarios (for deduplication testing)
    """
    
    print("üß† AICO Multi-Scenario Memory Evaluation Test")
    print("=" * 60)
    if reuse_user:
        print("üîÑ DEDUPLICATION TEST MODE: Reusing same user across all scenarios")
        print("=" * 60)
    
    evaluator = MemoryIntelligenceEvaluator(reuse_user=reuse_user)
    library = ScenarioLibrary()
    
    try:
        # Get the default 3 diverse scenarios
        scenario_names = library.get_default_multi_scenario_set()
        
        print(f"üìã Testing {len(scenario_names)} diverse scenarios:")
        for i, name in enumerate(scenario_names, 1):
            scenario = library.get_scenario(name)
            print(f"  {i}. {name}")
            print(f"     üìù {scenario.description}")
            print(f"     üéØ Difficulty: {scenario.difficulty_level}")
            print(f"     üí¨ Turns: {len(scenario.conversation_turns)}")
        
        print(f"\nüöÄ Starting evaluation...")
        
        # Run each scenario
        results = []
        for i, scenario_name in enumerate(scenario_names, 1):
            print(f"\n{'='*60}")
            print(f"üìä SCENARIO {i}/{len(scenario_names)}: {scenario_name}")
            print(f"{'='*60}")
            
            try:
                result = await evaluator.run_comprehensive_evaluation(scenario_name)
                results.append((scenario_name, result))
                
                print(f"\n‚úÖ Scenario Complete: {scenario_name}")
                print(f"üéØ Overall Score: {result.overall_score.percentage:.1f}%")
                print(f"üìà Key Metrics:")
                print(f"  Context Adherence........ {result.context_adherence.percentage:6.1f}%")
                print(f"  Knowledge Retention...... {result.knowledge_retention.percentage:6.1f}%")
                print(f"  Entity Extraction........ {result.entity_extraction.percentage:6.1f}%")
                
            except Exception as e:
                print(f"‚ùå Scenario failed: {e}")
                continue
        
        # Calculate compound score
        if len(results) > 1:
            print(f"\n{'='*60}")
            print(f"üìä COMPOUND EVALUATION RESULTS")
            print(f"{'='*60}")
            
            total_score = sum(result.overall_score.percentage for _, result in results)
            compound_score = total_score / len(results)
            
            print(f"üéØ Compound Overall Score: {compound_score:.1f}%")
            print(f"üìã Individual Results:")
            for scenario_name, result in results:
                color = "‚úÖ" if result.overall_score.percentage >= 85 else "‚ö†Ô∏è" if result.overall_score.percentage >= 70 else "‚ùå"
                print(f"  {color} {scenario_name}: {result.overall_score.percentage:.1f}%")
        
        print(f"\nüéâ Multi-scenario evaluation complete!")
        
    except Exception as e:
        print(f"‚ùå Evaluation failed: {e}")
        import traceback
        traceback.print_exc()
        return 1
    finally:
        await evaluator.cleanup()
    
    return 0

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="AICO Multi-Scenario Memory Evaluation")
    parser.add_argument("--reuse-user", action="store_true", 
                       help="Reuse same user across all scenarios (for deduplication testing)")
    args = parser.parse_args()
    
    exit_code = asyncio.run(test_multi_scenario(reuse_user=args.reuse_user))
    sys.exit(exit_code)
