# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: aico_modelservice.proto
# Protobuf Python Version: 6.32.0
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import runtime_version as _runtime_version
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
_runtime_version.ValidateProtobufRuntimeVersion(
    _runtime_version.Domain.PUBLIC,
    6,
    32,
    0,
    '',
    'aico_modelservice.proto'
)
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from google.protobuf import timestamp_pb2 as google_dot_protobuf_dot_timestamp__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x17\x61ico_modelservice.proto\x12\x11\x61ico.modelservice\x1a\x1fgoogle/protobuf/timestamp.proto\"\x0f\n\rHealthRequest\"\x9b\x02\n\x12\x43ompletionsRequest\x12\r\n\x05model\x18\x01 \x01(\t\x12\x38\n\x08messages\x18\x02 \x03(\x0b\x32&.aico.modelservice.ConversationMessage\x12\x0e\n\x06stream\x18\x03 \x01(\x08\x12\x18\n\x0btemperature\x18\x04 \x01(\x01H\x00\x88\x01\x01\x12\x17\n\nmax_tokens\x18\x05 \x01(\x05H\x01\x88\x01\x01\x12\x12\n\x05top_p\x18\x06 \x01(\x01H\x02\x88\x01\x01\x12\x13\n\x06system\x18\x07 \x01(\tH\x03\x88\x01\x01\x12\x12\n\x05think\x18\x08 \x01(\x08H\x04\x88\x01\x01\x42\x0e\n\x0c_temperatureB\r\n\x0b_max_tokensB\x08\n\x06_top_pB\t\n\x07_systemB\x08\n\x06_think\"\xab\x01\n\x0eStreamingChunk\x12\x12\n\nrequest_id\x18\x01 \x01(\t\x12\x0f\n\x07\x63ontent\x18\x02 \x01(\t\x12\x1b\n\x13\x61\x63\x63umulated_content\x18\x03 \x01(\t\x12\x0c\n\x04\x64one\x18\x04 \x01(\x08\x12\r\n\x05model\x18\x05 \x01(\t\x12\x16\n\ttimestamp\x18\x06 \x01(\x03H\x00\x88\x01\x01\x12\x14\n\x0c\x63ontent_type\x18\x07 \x01(\tB\x0c\n\n_timestamp\"\x0f\n\rModelsRequest\"!\n\x10ModelInfoRequest\x12\r\n\x05model\x18\x01 \x01(\t\"2\n\x11\x45mbeddingsRequest\x12\r\n\x05model\x18\x01 \x01(\t\x12\x0e\n\x06prompt\x18\x02 \x01(\t\"V\n\nNerRequest\x12\x0c\n\x04text\x18\x01 \x01(\t\x12\x14\n\x0c\x65ntity_types\x18\x02 \x03(\t\x12\x16\n\tthreshold\x18\x03 \x01(\x02H\x00\x88\x01\x01\x42\x0c\n\n_threshold\"I\n\x1bIntentClassificationRequest\x12\x0c\n\x04text\x18\x01 \x01(\t\x12\x12\n\x05model\x18\x02 \x01(\tH\x00\x88\x01\x01\x42\x08\n\x06_model\" \n\x10SentimentRequest\x12\x0c\n\x04text\x18\x01 \x01(\t\"\x0f\n\rStatusRequest\"\x15\n\x13OllamaStatusRequest\"\x15\n\x13OllamaModelsRequest\"\"\n\x11OllamaPullRequest\x12\r\n\x05model\x18\x01 \x01(\t\"$\n\x13OllamaRemoveRequest\x12\r\n\x05model\x18\x01 \x01(\t\"\x14\n\x12OllamaServeRequest\"\x17\n\x15OllamaShutdownRequest\"h\n\nTtsRequest\x12\x0c\n\x04text\x18\x01 \x01(\t\x12\x10\n\x08language\x18\x02 \x01(\t\x12\x12\n\x05speed\x18\x03 \x01(\x02H\x00\x88\x01\x01\x12\x12\n\x05voice\x18\x04 \x01(\tH\x01\x88\x01\x01\x42\x08\n\x06_speedB\x08\n\x06_voice\"O\n\x0eHealthResponse\x12\x0f\n\x07success\x18\x01 \x01(\x08\x12\x0e\n\x06status\x18\x02 \x01(\t\x12\x12\n\x05\x65rror\x18\x03 \x01(\tH\x00\x88\x01\x01\x42\x08\n\x06_error\"\x89\x01\n\x13\x43ompletionsResponse\x12\x0f\n\x07success\x18\x01 \x01(\x08\x12\x38\n\x06result\x18\x02 \x01(\x0b\x32#.aico.modelservice.CompletionResultH\x00\x88\x01\x01\x12\x12\n\x05\x65rror\x18\x03 \x01(\tH\x01\x88\x01\x01\x42\t\n\x07_resultB\x08\n\x06_error\"m\n\x0eModelsResponse\x12\x0f\n\x07success\x18\x01 \x01(\x08\x12,\n\x06models\x18\x02 \x03(\x0b\x32\x1c.aico.modelservice.ModelInfo\x12\x12\n\x05\x65rror\x18\x03 \x01(\tH\x00\x88\x01\x01\x42\x08\n\x06_error\"\x85\x01\n\x11ModelInfoResponse\x12\x0f\n\x07success\x18\x01 \x01(\x08\x12\x35\n\x07\x64\x65tails\x18\x02 \x01(\x0b\x32\x1f.aico.modelservice.ModelDetailsH\x00\x88\x01\x01\x12\x12\n\x05\x65rror\x18\x03 \x01(\tH\x01\x88\x01\x01\x42\n\n\x08_detailsB\x08\n\x06_error\"V\n\x12\x45mbeddingsResponse\x12\x0f\n\x07success\x18\x01 \x01(\x08\x12\x11\n\tembedding\x18\x02 \x03(\x01\x12\x12\n\x05\x65rror\x18\x03 \x01(\tH\x00\x88\x01\x01\x42\x08\n\x06_error\"\xcc\x01\n\x0bNerResponse\x12\x0f\n\x07success\x18\x01 \x01(\x08\x12>\n\x08\x65ntities\x18\x02 \x03(\x0b\x32,.aico.modelservice.NerResponse.EntitiesEntry\x12\x12\n\x05\x65rror\x18\x03 \x01(\tH\x00\x88\x01\x01\x1aN\n\rEntitiesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12,\n\x05value\x18\x02 \x01(\x0b\x32\x1d.aico.modelservice.EntityList:\x02\x38\x01\x42\x08\n\x06_error\"G\n\nEntityList\x12\x39\n\x08\x65ntities\x18\x01 \x03(\x0b\x32\'.aico.modelservice.EntityWithConfidence\"8\n\x14\x45ntityWithConfidence\x12\x0c\n\x04text\x18\x01 \x01(\t\x12\x12\n\nconfidence\x18\x02 \x01(\x02\"\xf9\x02\n\x1cIntentClassificationResponse\x12\x0f\n\x07success\x18\x01 \x01(\x08\x12\x18\n\x10predicted_intent\x18\x02 \x01(\t\x12\x12\n\nconfidence\x18\x03 \x01(\x01\x12\x19\n\x11\x64\x65tected_language\x18\x04 \x01(\t\x12\x19\n\x11inference_time_ms\x18\x05 \x01(\x01\x12\x44\n\x17\x61lternative_predictions\x18\x06 \x03(\x0b\x32#.aico.modelservice.IntentPrediction\x12O\n\x08metadata\x18\x07 \x03(\x0b\x32=.aico.modelservice.IntentClassificationResponse.MetadataEntry\x12\x12\n\x05\x65rror\x18\x08 \x01(\tH\x00\x88\x01\x01\x1a/\n\rMetadataEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x42\x08\n\x06_error\"6\n\x10IntentPrediction\x12\x0e\n\x06intent\x18\x01 \x01(\t\x12\x12\n\nconfidence\x18\x02 \x01(\x01\"i\n\x11SentimentResponse\x12\x0f\n\x07success\x18\x01 \x01(\x08\x12\x11\n\tsentiment\x18\x02 \x01(\t\x12\x12\n\nconfidence\x18\x03 \x01(\x01\x12\x12\n\x05\x65rror\x18\x04 \x01(\tH\x00\x88\x01\x01\x42\x08\n\x06_error\"\x81\x01\n\x0eStatusResponse\x12\x0f\n\x07success\x18\x01 \x01(\x08\x12\x35\n\x06status\x18\x02 \x01(\x0b\x32 .aico.modelservice.ServiceStatusH\x00\x88\x01\x01\x12\x12\n\x05\x65rror\x18\x03 \x01(\tH\x01\x88\x01\x01\x42\t\n\x07_statusB\x08\n\x06_error\"\x86\x01\n\x14OllamaStatusResponse\x12\x0f\n\x07success\x18\x01 \x01(\x08\x12\x34\n\x06status\x18\x02 \x01(\x0b\x32\x1f.aico.modelservice.OllamaStatusH\x00\x88\x01\x01\x12\x12\n\x05\x65rror\x18\x03 \x01(\tH\x01\x88\x01\x01\x42\t\n\x07_statusB\x08\n\x06_error\"s\n\x14OllamaModelsResponse\x12\x0f\n\x07success\x18\x01 \x01(\x08\x12,\n\x06models\x18\x02 \x03(\x0b\x32\x1c.aico.modelservice.ModelInfo\x12\x12\n\x05\x65rror\x18\x03 \x01(\tH\x00\x88\x01\x01\x42\x08\n\x06_error\"e\n\x12OllamaPullResponse\x12\x0f\n\x07success\x18\x01 \x01(\x08\x12\x14\n\x07message\x18\x02 \x01(\tH\x00\x88\x01\x01\x12\x12\n\x05\x65rror\x18\x03 \x01(\tH\x01\x88\x01\x01\x42\n\n\x08_messageB\x08\n\x06_error\"g\n\x14OllamaRemoveResponse\x12\x0f\n\x07success\x18\x01 \x01(\x08\x12\x14\n\x07message\x18\x02 \x01(\tH\x00\x88\x01\x01\x12\x12\n\x05\x65rror\x18\x03 \x01(\tH\x01\x88\x01\x01\x42\n\n\x08_messageB\x08\n\x06_error\"f\n\x13OllamaServeResponse\x12\x0f\n\x07success\x18\x01 \x01(\x08\x12\x14\n\x07message\x18\x02 \x01(\tH\x00\x88\x01\x01\x12\x12\n\x05\x65rror\x18\x03 \x01(\tH\x01\x88\x01\x01\x42\n\n\x08_messageB\x08\n\x06_error\"i\n\x16OllamaShutdownResponse\x12\x0f\n\x07success\x18\x01 \x01(\x08\x12\x14\n\x07message\x18\x02 \x01(\tH\x00\x88\x01\x01\x12\x12\n\x05\x65rror\x18\x03 \x01(\tH\x01\x88\x01\x01\x42\n\n\x08_messageB\x08\n\x06_error\"i\n\x0eTtsStreamChunk\x12\x12\n\naudio_data\x18\x01 \x01(\x0c\x12\x13\n\x0bsample_rate\x18\x02 \x01(\x05\x12\x10\n\x08is_final\x18\x03 \x01(\x08\x12\x12\n\x05\x65rror\x18\x04 \x01(\tH\x00\x88\x01\x01\x42\x08\n\x06_error\"4\n\x13\x43onversationMessage\x12\x0c\n\x04role\x18\x01 \x01(\t\x12\x0f\n\x07\x63ontent\x18\x02 \x01(\t\"\xe2\x03\n\x10\x43ompletionResult\x12\r\n\x05model\x18\x01 \x01(\t\x12.\n\ncreated_at\x18\x02 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x37\n\x07message\x18\x03 \x01(\x0b\x32&.aico.modelservice.ConversationMessage\x12\x0c\n\x04\x64one\x18\x04 \x01(\x08\x12\x1b\n\x0etotal_duration\x18\x05 \x01(\x03H\x00\x88\x01\x01\x12\x1a\n\rload_duration\x18\x06 \x01(\x03H\x01\x88\x01\x01\x12\x1e\n\x11prompt_eval_count\x18\x07 \x01(\x03H\x02\x88\x01\x01\x12!\n\x14prompt_eval_duration\x18\x08 \x01(\x03H\x03\x88\x01\x01\x12\x17\n\neval_count\x18\t \x01(\x03H\x04\x88\x01\x01\x12\x1a\n\reval_duration\x18\n \x01(\x03H\x05\x88\x01\x01\x12\x15\n\x08thinking\x18\x0b \x01(\tH\x06\x88\x01\x01\x42\x11\n\x0f_total_durationB\x10\n\x0e_load_durationB\x14\n\x12_prompt_eval_countB\x17\n\x15_prompt_eval_durationB\r\n\x0b_eval_countB\x10\n\x0e_eval_durationB\x0b\n\t_thinking\"\xba\x01\n\tModelInfo\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\r\n\x05model\x18\x02 \x01(\t\x12/\n\x0bmodified_at\x18\x03 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x0c\n\x04size\x18\x04 \x01(\x03\x12\x0e\n\x06\x64igest\x18\x05 \x01(\t\x12\x35\n\x07\x64\x65tails\x18\x06 \x01(\x0b\x32\x1f.aico.modelservice.ModelDetailsH\x00\x88\x01\x01\x42\n\n\x08_details\"\x8a\x01\n\x0cModelDetails\x12\x14\n\x0cparent_model\x18\x01 \x01(\t\x12\x0e\n\x06\x66ormat\x18\x02 \x01(\t\x12\x0e\n\x06\x66\x61mily\x18\x03 \x01(\t\x12\x10\n\x08\x66\x61milies\x18\x04 \x03(\t\x12\x16\n\x0eparameter_size\x18\x05 \x01(\x03\x12\x1a\n\x12quantization_level\x18\x06 \x01(\x03\"\x84\x01\n\rServiceStatus\x12\x0f\n\x07version\x18\x01 \x01(\t\x12\x16\n\x0eollama_running\x18\x02 \x01(\x08\x12\x16\n\x0eollama_version\x18\x03 \x01(\t\x12\x1b\n\x13loaded_models_count\x18\x04 \x01(\x05\x12\x15\n\rloaded_models\x18\x05 \x03(\t\"c\n\x0cOllamaStatus\x12\x0f\n\x07running\x18\x01 \x01(\x08\x12\x0f\n\x07version\x18\x02 \x01(\t\x12\x0c\n\x04host\x18\x03 \x01(\t\x12\x0c\n\x04port\x18\x04 \x01(\x05\x12\x15\n\rloaded_models\x18\x05 \x03(\tBa\n(industries.boeni.aico.proto.modelserviceP\x01Z3github.com/boeni-industries/aico/proto/modelserviceb\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'aico_modelservice_pb2', _globals)
if not _descriptor._USE_C_DESCRIPTORS:
  _globals['DESCRIPTOR']._loaded_options = None
  _globals['DESCRIPTOR']._serialized_options = b'\n(industries.boeni.aico.proto.modelserviceP\001Z3github.com/boeni-industries/aico/proto/modelservice'
  _globals['_NERRESPONSE_ENTITIESENTRY']._loaded_options = None
  _globals['_NERRESPONSE_ENTITIESENTRY']._serialized_options = b'8\001'
  _globals['_INTENTCLASSIFICATIONRESPONSE_METADATAENTRY']._loaded_options = None
  _globals['_INTENTCLASSIFICATIONRESPONSE_METADATAENTRY']._serialized_options = b'8\001'
  _globals['_HEALTHREQUEST']._serialized_start=79
  _globals['_HEALTHREQUEST']._serialized_end=94
  _globals['_COMPLETIONSREQUEST']._serialized_start=97
  _globals['_COMPLETIONSREQUEST']._serialized_end=380
  _globals['_STREAMINGCHUNK']._serialized_start=383
  _globals['_STREAMINGCHUNK']._serialized_end=554
  _globals['_MODELSREQUEST']._serialized_start=556
  _globals['_MODELSREQUEST']._serialized_end=571
  _globals['_MODELINFOREQUEST']._serialized_start=573
  _globals['_MODELINFOREQUEST']._serialized_end=606
  _globals['_EMBEDDINGSREQUEST']._serialized_start=608
  _globals['_EMBEDDINGSREQUEST']._serialized_end=658
  _globals['_NERREQUEST']._serialized_start=660
  _globals['_NERREQUEST']._serialized_end=746
  _globals['_INTENTCLASSIFICATIONREQUEST']._serialized_start=748
  _globals['_INTENTCLASSIFICATIONREQUEST']._serialized_end=821
  _globals['_SENTIMENTREQUEST']._serialized_start=823
  _globals['_SENTIMENTREQUEST']._serialized_end=855
  _globals['_STATUSREQUEST']._serialized_start=857
  _globals['_STATUSREQUEST']._serialized_end=872
  _globals['_OLLAMASTATUSREQUEST']._serialized_start=874
  _globals['_OLLAMASTATUSREQUEST']._serialized_end=895
  _globals['_OLLAMAMODELSREQUEST']._serialized_start=897
  _globals['_OLLAMAMODELSREQUEST']._serialized_end=918
  _globals['_OLLAMAPULLREQUEST']._serialized_start=920
  _globals['_OLLAMAPULLREQUEST']._serialized_end=954
  _globals['_OLLAMAREMOVEREQUEST']._serialized_start=956
  _globals['_OLLAMAREMOVEREQUEST']._serialized_end=992
  _globals['_OLLAMASERVEREQUEST']._serialized_start=994
  _globals['_OLLAMASERVEREQUEST']._serialized_end=1014
  _globals['_OLLAMASHUTDOWNREQUEST']._serialized_start=1016
  _globals['_OLLAMASHUTDOWNREQUEST']._serialized_end=1039
  _globals['_TTSREQUEST']._serialized_start=1041
  _globals['_TTSREQUEST']._serialized_end=1145
  _globals['_HEALTHRESPONSE']._serialized_start=1147
  _globals['_HEALTHRESPONSE']._serialized_end=1226
  _globals['_COMPLETIONSRESPONSE']._serialized_start=1229
  _globals['_COMPLETIONSRESPONSE']._serialized_end=1366
  _globals['_MODELSRESPONSE']._serialized_start=1368
  _globals['_MODELSRESPONSE']._serialized_end=1477
  _globals['_MODELINFORESPONSE']._serialized_start=1480
  _globals['_MODELINFORESPONSE']._serialized_end=1613
  _globals['_EMBEDDINGSRESPONSE']._serialized_start=1615
  _globals['_EMBEDDINGSRESPONSE']._serialized_end=1701
  _globals['_NERRESPONSE']._serialized_start=1704
  _globals['_NERRESPONSE']._serialized_end=1908
  _globals['_NERRESPONSE_ENTITIESENTRY']._serialized_start=1820
  _globals['_NERRESPONSE_ENTITIESENTRY']._serialized_end=1898
  _globals['_ENTITYLIST']._serialized_start=1910
  _globals['_ENTITYLIST']._serialized_end=1981
  _globals['_ENTITYWITHCONFIDENCE']._serialized_start=1983
  _globals['_ENTITYWITHCONFIDENCE']._serialized_end=2039
  _globals['_INTENTCLASSIFICATIONRESPONSE']._serialized_start=2042
  _globals['_INTENTCLASSIFICATIONRESPONSE']._serialized_end=2419
  _globals['_INTENTCLASSIFICATIONRESPONSE_METADATAENTRY']._serialized_start=2362
  _globals['_INTENTCLASSIFICATIONRESPONSE_METADATAENTRY']._serialized_end=2409
  _globals['_INTENTPREDICTION']._serialized_start=2421
  _globals['_INTENTPREDICTION']._serialized_end=2475
  _globals['_SENTIMENTRESPONSE']._serialized_start=2477
  _globals['_SENTIMENTRESPONSE']._serialized_end=2582
  _globals['_STATUSRESPONSE']._serialized_start=2585
  _globals['_STATUSRESPONSE']._serialized_end=2714
  _globals['_OLLAMASTATUSRESPONSE']._serialized_start=2717
  _globals['_OLLAMASTATUSRESPONSE']._serialized_end=2851
  _globals['_OLLAMAMODELSRESPONSE']._serialized_start=2853
  _globals['_OLLAMAMODELSRESPONSE']._serialized_end=2968
  _globals['_OLLAMAPULLRESPONSE']._serialized_start=2970
  _globals['_OLLAMAPULLRESPONSE']._serialized_end=3071
  _globals['_OLLAMAREMOVERESPONSE']._serialized_start=3073
  _globals['_OLLAMAREMOVERESPONSE']._serialized_end=3176
  _globals['_OLLAMASERVERESPONSE']._serialized_start=3178
  _globals['_OLLAMASERVERESPONSE']._serialized_end=3280
  _globals['_OLLAMASHUTDOWNRESPONSE']._serialized_start=3282
  _globals['_OLLAMASHUTDOWNRESPONSE']._serialized_end=3387
  _globals['_TTSSTREAMCHUNK']._serialized_start=3389
  _globals['_TTSSTREAMCHUNK']._serialized_end=3494
  _globals['_CONVERSATIONMESSAGE']._serialized_start=3496
  _globals['_CONVERSATIONMESSAGE']._serialized_end=3548
  _globals['_COMPLETIONRESULT']._serialized_start=3551
  _globals['_COMPLETIONRESULT']._serialized_end=4033
  _globals['_MODELINFO']._serialized_start=4036
  _globals['_MODELINFO']._serialized_end=4222
  _globals['_MODELDETAILS']._serialized_start=4225
  _globals['_MODELDETAILS']._serialized_end=4363
  _globals['_SERVICESTATUS']._serialized_start=4366
  _globals['_SERVICESTATUS']._serialized_end=4498
  _globals['_OLLAMASTATUS']._serialized_start=4500
  _globals['_OLLAMASTATUS']._serialized_end=4599
# @@protoc_insertion_point(module_scope)
